# -*- coding: utf-8 -*-
"""forest classifier using fine tuning ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13ASNw0qhD4H94Z7zngKw8mpiFtufTDv1
"""

from google.colab import drive
drive.mount('/content/drive')

zip_path = "/content/drive/MyDrive/datasets/forest classifier.zip"
extract_path = "/content/forest_dataset"

import zipfile, os

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("‚úÖ Extracted to:", extract_path)
print("üìÇ Folders inside dataset:", os.listdir(extract_path))

import zipfile
import os

# path to your zip file
zip_path = "/content/forest_dataset/archive (50).zip"
extract_path = "/content/forest_dataset_real"

# unzip the file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("‚úÖ Extracted to:", extract_path)
print("üìÇ Folders inside dataset:", os.listdir(extract_path))

os.listdir(extract_path)

test_path =os.path.join(extract_path,"seg_test/seg_test")
train_path = os.path.join(extract_path,"seg_train/seg_train")
seg_pred_path=os.path.join(extract_path,'seg_pred/seg_pred')

print("Traing path is ",train_path)
print("Testing path is ",test_path)
print("seg_pred path is ",seg_pred_path)

print("Training subclasses is ", os.listdir(train_path))
print("Testing subclasses is ",os.listdir(test_path))
print("pred_seg subclasses is ",os.listdir(seg_pred_path))

from IPython.display import Image
display(Image(os.path.join(seg_pred_path,os.listdir(seg_pred_path)[3])))

from PIL import Image
Image.open(os.path.join(train_path,"forest",os.listdir(os.path.join(train_path,"forest"))[4]))

Image.open(os.path.join(test_path,"forest",os.listdir(os.path.join(test_path,"forest"))[9]))

import cv2
import matplotlib.pyplot as plt
img = cv2.imread(os.path.join(train_path,"buildings",os.listdir(os.path.join(train_path,"buildings"))[4]))
plt.imshow(img)
plt.axis('off')
plt.show()

# now apply vgg16 model
import tensorflow
from tensorflow import keras
from tensorflow.keras import layers

conv_base =keras.applications.vgg16.VGG16(
    weights='imagenet',
    include_top=False,
    input_shape=(180,180,3)
)

conv_base.summary()

from tensorflow.keras.utils import image_dataset_from_directory
batch_size = 64
train_data = image_dataset_from_directory(train_path,label_mode='int',image_size=(180,180),batch_size = batch_size)

test_data =image_dataset_from_directory(test_path,label_mode='int',image_size=(180,180),batch_size=batch_size)

conv_base.trainable = True
for layer in conv_base.layers[:-4]:
 layer.trainable = False

data_augmentation =keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1)

])

# now dense classifer
model = keras.Sequential([
    layers.Input(shape=(180,180,3)),
    data_augmentation,
    conv_base,
    layers.Flatten(),
    layers.Dense(64,activation="relu"),
    layers.Dropout(0.3),
    layers.BatchNormalization(),
    layers.Dense(len(train_data.class_names),activation="softmax")
])

model.summary()

model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),loss = "sparse_categorical_crossentropy",metrics=["accuracy"])

callback = keras.callbacks.ModelCheckpoint(
    filepath="bhot acha record save in.keras",
     monitor='val_loss',
     save_best_only=True,
)

history= model.fit(train_data,epochs=10,validation_data=test_data,callbacks=callback)

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'],label = "accuracy")
plt.plot(history.history['val_accuracy'],label = "val_accuracy")
plt.title("Accuracy and val_accuracy")
plt.show()

import matplotlib.pyplot as plt
plt.plot(history.history['loss'],label = "loss")
plt.plot(history.history['val_loss'],label = "val_loss")
plt.title("loss and val_loss")
plt.show()

import gradio as gr
import cv2
import numpy as np
import matplotlib.pyplot as plt

# agar model save hai to load karo
# from tensorflow import keras
# model = keras.models.load_model("tumhara_model_path.h5")

class_names = ['street', 'buildings', 'glacier', 'forest', 'sea', 'mountain']

def predict_image(img):
    # Preprocess
    img = cv2.resize(img, (180,180))
    img = img / 255.0
    img = np.expand_dims(img, axis=0)

    # Prediction
    pred = model.predict(img)[0]   # shape (6,)
    pred_class = class_names[np.argmax(pred)]

    # Bar chart banao
    fig, ax = plt.subplots()
    ax.bar(class_names, pred)
    ax.set_ylabel("Probability")
    ax.set_title(f"Prediction: {pred_class}")
    plt.xticks(rotation=45)

    return pred_class, fig

# Gradio interface
demo = gr.Interface(
    fn=predict_image,
    inputs=gr.Image(type="numpy"),
    outputs=["text", gr.Plot()],
    title="üåç Scene Classifier"
)

demo.launch()





